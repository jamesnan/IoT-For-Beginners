
# 使用 IoT 设备识别语音

![本课的 sketchnote 概述](../../../../sketchnotes/lesson-21.jpg)

> [Nitya Narasimhan](https://github.com/nitya) 的草图笔记。单击图像查看放大版本。

该视频概述了 Azure 语音服务，这是本课程将介绍的主题：

[![如何开始使用 Microsoft Azure YouTube 频道中的认知服务语音资源](https://img.youtube.com/vi/iW0Fw0l3mrA/0.jpg)](https://www.youtube.com/watch?v=iW0Fw0l3mrA)


> 🎥 点击上图观看视频

## 课前测验

[课前测验](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/41)

## 介绍

`Alexa，设置 12 分钟计时器`

`Alexa，计时器状态`

`Alexa，设置一个名为`蒸汽西兰花`的 8 分钟计时器`

智能设备变得越来越普遍。不仅像 HomePods、Echos 和 Google Homes 这样的智能扬声器，而且还嵌入到我们的手机、手表，甚至灯具和恒温器中。

> 💁 我家里至少有 19 台带有语音助手的设备，而这只是我所知道的！

语音控制允许行动受限的人与设备交互，从而提高了可访问性。无论是永久性残疾（例如天生没有手臂），还是暂时性残疾（例如手臂骨折），还是双手忙着购物或带小孩，能够用声音而不是双手来控制我们的房子，打开了一个充满活力的世界。使用权。在处理婴儿换尿布和不守规矩的幼儿时大喊`嘿 Siri，关上我的车库门`可能是对生活的微小但有效的改善。

语音助手更流行的用途之一是设置计时器，尤其是厨房计时器。只需用声音即可设置多个计时器，这对厨房来说是一个很大的帮助——无需停止揉面团、搅拌汤或清理手中的饺子馅来使用物理计时器。

在本课程中，您将学习如何在物联网设备中构建语音识别。您将了解如何将麦克风用作传感器、如何从连接到 IoT 设备的麦克风捕获音频，以及如何使用 AI 将听到的内容转换为文本。在本项目的其余部分中，您将构建一个智能厨房计时器，能够使用多种语言的语音设置计时器。

在本课中，我们将介绍：

* [麦克风](#麦克风)
* [从 IoT 设备捕获音频](#从IoT设备捕获音频)
* [语音转文字](#语音转文字)
* [将语音转换为文本](#将语音转换为文本)

## 麦克风

麦克风是将声波转换为电信号的模拟传感器。空气中的振动会导致麦克风中的组件发生微小的移动，从而导致电信号发生微小的变化。然后这些变化被放大以产生电输出。

### 麦克风类型

麦克风有多种类型：

* 动态 - 动态麦克风的磁铁附着在移动隔膜上，该隔膜在线圈中移动，产生电流。这与大多数扬声器相反，大多数扬声器使用电流移动线圈中的磁铁，移动振膜来产生声音。这意味着扬声器可以用作动圈麦克风，动圈麦克风也可以用作扬声器。在诸如对讲机之类的设备中，用户要么在听，要么在说话，但不能同时听和说，一台设备可以同时充当扬声器和麦克风。

    动圈麦克风不需要电源即可工作，电信号完全由麦克风产生。

    ![Patti Smith 对着 Shure SM58（动态心型）麦克风唱歌](../../../../images/dynamic-mic.jpg)

* 丝带 - 丝带麦克风与动圈麦克风类似，不同之处在于它们具有金属丝带而不是振膜。该带在磁场中移动，产生电流。与动圈麦克风一样，带式麦克风不需要电源即可工作。

    ![Edmund Lowe，美国演员，站在无线电麦克风前（标记为 (NBC) Blue Network），手持剧本，1942 年](../../../../images/ribbon-mic.jpg)

* 电容式麦克风 - 电容式麦克风具有薄金属振膜和固定金属背板。对这两者施加电流，当隔膜振动时，板之间的静电荷发生变化，从而产生信号。电容式麦克风需要电源才能工作 - 称为`幻象电源`。

    ![AKG Acoustics 出品的 C451B 小振膜电容式麦克风](../../../../images/condenser-mic.jpg)

* MEMS - 微机电系统麦克风或 MEMS 是芯片上的麦克风。它们具有蚀刻在硅芯片上的压敏膜片，其工作原理与电容式麦克风类似。这些麦克风可以很小，并集成到电路中。

    ![电路板上的 MEMS 麦克风](../../../../images/mems-microphone.png)

    在上图中，标记为 **LEFT** 的芯片是 MEMS 麦克风，具有小于一毫米宽的微小隔膜。

✅ 做一些研究：您周围有哪些麦克风 - 无论是在您的计算机、手机、耳机还是其他设备中。它们是什么类型的麦克风？

### 数字音频

音频是一种携带非常细粒度信息的模拟信号。为了将此信号转换为数字信号，每秒需要对音频进行数千次采样。

> 🎓 采样是将音频信号转换为代表该时间点信号的数字值。

![显示信号的折线图，具有固定间隔的离散点](../../../../images/sampling.png)

数字音频使用脉冲编码调制（PCM）进行采样。 PCM 涉及读取信​​号的电压，并使用定义的大小选择最接近该电压的离散值。

> 💁 您可以将 PCM 视为脉冲宽度调制的传感器版本，或 PWM（PWM 在[入门项目的第 3 课](../../../1-getting-started/lessons/3-sensors-and-actuators/README.md#pulse-width-modulation))。 PCM 涉及将模拟信号转换为数字信号，PWM 涉及将数字信号转换为模拟信号。

例如，大多数流媒体音乐服务提供 16 位或 24 位音频。这意味着它们将电压转换为适合 16 位整数或 24 位整数的值。 16 位音频将该值拟合为 -32,768 到 32,767 范围内的数字，24 位音频将该值拟合为 -8,388,608 到 8,388,607 范围内的数字。位数越多，样本就越接近我们耳朵实际听到的声音。

> 💁 您可能有 8 位音频，通常称为 LoFi。这是仅使用 8 位采样的音频，因此为 -128 到 127。由于硬件限制，第一个计算机音频仅限于 8 位，因此这在复古游戏中经常出现。

这些样本每秒采集数千次，使用以 KHz（每秒数千个读数）为单位测量的明确定义的采样率。流媒体音乐服务大多数音频使用 48KHz，但某些`无损`音频使用高达 96KHz 甚至 192KHz。在某种程度上，采样率越高，音频就越接近原始音频。人类是否能够区分 48KHz 以上的频率存在争议。

✅ 做一些研究：如果您使用流媒体音乐服务，它使用什么采样率和大小？如果您使用 CD，CD 音频的采样率和大小是多少？

音频数据有多种不同的格式。您可能听说过 mp3 文件 - 经过压缩以使其更小而不损失任何质量的音频数据。未压缩的音频通常存储为 WAV 文件 - 该文件具有 44 字节的标头信息，后跟原始音频数据。标头包含诸如采样率（例如 16KHz 为 16000）和样本大小（16 位为 16）以及通道数等信息。在标头之后，WAV 文件包含原始音频数据。

> 🎓 通道是指有多少个不同的音频流组成音频。例如，对于左右立体声音频，将有 2 个声道。对于家庭影院系统的 7.1 环绕声，该值为 8。

### 音频数据大小

音频数据比较大。例如，以 16KHz（对于语音转文本模型而言足够好的速率）捕获未压缩的 16 位音频，每秒音频需要 32KB 的数据：

* 16 位表示每个样本 2 个字节（1 个字节为 8 位）。
* 16KHz 是每秒 16,000 个样本。
* 16,000 x 2 字节 = 每秒 32,000 字节。

这听起来像是少量数据，但如果您使用内存有限的微控制器，这可能会很多。例如，Wio终端有192KB的内存，需要存储程序代码和变量。即使您的程序代码很小，您也无法捕获超过 5 秒的音频。

微控制器可以访问附加存储，例如 SD 卡或闪存。在构建捕获音频的物联网设备时，您不仅需要确保拥有额外的存储空间，而且您的代码将从麦克风捕获的音频直接写入该存储空间，并且在将其发送到云端时，您可以从存储流式传输到网络要求。这样，您可以通过尝试将整个音频数据块一次保存在内存中来避免内存不足。

## 从 IoT 设备捕获音频

您的物联网设备可以连接到麦克风来捕获音频，准备转换为文本。它还可以连接到扬声器以输出音频。在后面的课程中，这将用于提供音频反馈，但现在设置扬声器来测试麦克风很有用。

### 任务 - 配置您的麦克风和扬声器

按照相关指南为您的 IoT 设备配置麦克风和扬声器：

* [Arduino - Wio 终端](../wio-terminal-microphone.md)
* [单板计算机-Raspberry Pi](../pi-microphone.md)
* [单板机-虚拟设备](../virtual-device-microphone.md)

### 任务 - 捕获音频

按照相关指南在 IoT 设备上捕获音频：

* [Arduino - Wio 终端](../wio-terminal-audio.md)
* [单板计算机-Raspberry Pi](../pi-audio.md)
* [单板机-虚拟设备](../virtual-device-audio.md)

## 语音转文字

语音转文本或语音识别涉及使用人工智能将音频信号中的单词转换为文本。

### 语音识别模型

为了将语音转换为文本，音频信号的样本被分组在一起，并输入到基于循环神经网络 (RNN) 的机器学习模型中。这是一种机器学习模型，可以使用先前的数据来对传入数据做出决策。例如，RNN 可以检测一个音频样本块为声音`Hel`，当它收到另一个它认为是声音`lo`的音频样本时，它可以将其与前一个声音结合起来，发现`Hello`是一个有效的单词并选择它作为结果。

ML 模型每次总是接受相同大小的数据。您在前面的课程中构建的图像分类器将图像大小调整为固定大小并对其进行处理。与语音模型相同，它们必须处理固定大小的音频块。语音模型需要能够组合多个预测的输出以获得答案，以使其能够区分`Hi`和`Highway`，或者`flock`和`floccinaucinihilipilification`。

语音模型也足够先进，可以理解上下文，并且可以在处理更多声音时纠正它们检测到的单词。例如，如果您说`我去商店买了两个香蕉和一个苹果`，您将使用三个听起来相同但拼写不同的单词 - to、two 和 Too。语音模型能够理解上下文并使用单词的适当拼写。

> 💁 一些语音服务允许定制，使其在工厂等嘈杂环境中或使用化学名称等行业特定单词时更好地工作。这些自定义内容通过提供示例音频和转录进行训练，并使用迁移学习进行工作，这与您在之前的课程中仅使用少量图像训练图像分类器的方式相同。

## 隐私

在消费者物联网设备中使用语音转文本时，隐私非常重要。这些设备连续收听音频，因此作为消费者，您不希望您所说的所有内容都发送到云端并转换为文本。这不仅会使用大量的互联网带宽，还会产生巨大的隐私影响，特别是当一些智能设备制造商随机选择音频[人类根据生成的文本进行验证以帮​​助改进他们的模型](https://www.theverge.com/2019/4/10/18305378/amazon-alexa-ai-voice-assistant-annotation-listen-private-recordings)。

您只希望智能设备在您使用时将音频发送到云端进行处理，而不是在它听到家中的音频（可能包括私人会议或亲密互动的音频）时将其发送到云端进行处理。大多数智能设备的工作方式是使用*唤醒词*，即`Alexa`、`Hey Siri`或`OK Google`等关键短语，使设备`唤醒`并聆听您所说的内容直到它检测到您的讲话中断，表明您已完成与设备的通话。

> 🎓 唤醒词检测也称为*关键字识别*或*关键字识别*。

这些唤醒词是在设备上检测到的，而不是在云端检测到的。这些智能设备具有在设备上运行的小型人工智能模型，用于侦听唤醒工作，当检测到唤醒工作时，开始将音频流式传输到云端进行识别。这些模型非常专业，只听唤醒词。

> 💁 一些科技公司正在为其设备添加更多隐私，并在设备上进行一些语音到文本的转换。 Apple 宣布，作为 2021 年 iOS 和 macOS 更新的一部分，他们将支持设备上的语音到文本转换，并且能够在无需使用云的情况下处理许多请求。这要归功于他们的设备中拥有可以运行机器学习模型的强大处理器。

✅ 您认为存储发送到云端的音频对隐私和道德有何影响？是否应该存储该音频？如果是，如何存储？您认为执法过程中使用录音对于隐私的丧失来说是一个很好的权衡吗？

唤醒词检测通常使用 TinyML 技术，即将 ML 模型转换为能够在微控制器上运行。这些模型体积小，运行时消耗的电力很少。

为了避免训练和使用唤醒词模型的复杂性，您在本课程中构建的智能计时器将使用一个按钮来打开语音识别。

> 💁 如果您想尝试创建唤醒词检测模型以在 Wio 终端或 Raspberry Pi 上运行，请查看此[通过 Edge Impulse 回复您的语音教程](https://docs.edgeimpulse.com/docs/responding-to-your-voice)。如果您想使用计算机执行此操作，可以尝试 [Microsoft 文档中的自定义关键字快速入门](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn)。

## 将语音转换为文本

![语音服务徽标](../../../../images/azure-speech-logo.png)

就像早期项目中的图像分类一样，有预构建的人工智能服务可以将语音作为音频文件并将其转换为文本。一旦此类服务成为语音服务，即认知服务的一部分，您就可以在应用程序中使用预构建的人工智能服务。

### 任务 - 配置语音 AI 资源

1.为此项目创建一个名为`smart-timer`的资源组

1. 使用以下命令创建自由言论资源：

    ```sh
    az cognitiveservices account create --name smart-timer \
                                        --resource-group smart-timer \
                                        --kind SpeechServices \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    替换 `<location>` 为您在创建资源组时使用的位置。

1. 您需要一个 API 密钥才能从您的代码访问语音资源。运行以下命令获取密钥：

    ```sh
    az cognitiveservices account keys list --name smart-timer \
                                           --resource-group smart-timer \
                                           --output table
    ```

    获取其中一把钥匙的副本。

### 任务 - 将语音转换为文本

完成相关指南，在 IoT 设备上将语音转换为文本：

* [Arduino - Wio 终端](../wio-terminal-speech-to-text.md)
* [单板计算机-Raspberry Pi](../pi-speech-to-text.md)
* [单板机-虚拟设备](../virtual-device-speech-to-text.md)

---

## 🚀 挑战

语音识别已经存在很长时间了，并且正在不断改进。研究当前的能力并比较这些能力如何随着时间的推移而发展，包括机器转录与人类相比的准确程度。

您认为语音识别的未来会怎样？

## 课后测验

[课后测验](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/42)

## 复习与自学

* 了解不同麦克风类型及其工作原理 [Musician's HQ 上的文章《动圈麦克风和电容麦克风有什么区别》](https://musicianshq.com/whats-the-difference-between-dynamic-and-condenser-microphones/)。
* 有关认知服务语音服务的更多信息，请参阅 [Microsoft Docs 上的语音服务文档](https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=academic-17441-jabenn)
* 请阅读 [Microsoft Docs 上的关键字识别文档](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn)

## 任务

[](../assignment.md)

    
   